{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your free ringtone is waiting to be collected....</td>\n",
       "      <td>PO Box 5249</td>\n",
       "      <td>MK17 92H. 450Ppw 16\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\Wen u miss someone</td>\n",
       "      <td>the person is definitely special for u..... B...</td>\n",
       "      <td>why to miss them</td>\n",
       "      <td>just Keep-in-touch\\\" gdeve..\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ham</td>\n",
       "      <td>\\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...</td>\n",
       "      <td>HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac sun0819 posts HELLO:\\You seem cool</td>\n",
       "      <td>wanted to say hi. HI!!!\\\" Stop? Send STOP to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>this wont even start........ Datz confidence..\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2  \\\n",
       "95   spam  Your free ringtone is waiting to be collected....   \n",
       "281   ham                                \\Wen u miss someone   \n",
       "444   ham  \\HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAR...   \n",
       "671  spam         SMS. ac sun0819 posts HELLO:\\You seem cool   \n",
       "710   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "\n",
       "                                            Unnamed: 2             Unnamed: 3  \\\n",
       "95                                         PO Box 5249   MK17 92H. 450Ppw 16\"   \n",
       "281   the person is definitely special for u..... B...       why to miss them   \n",
       "444   HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE ...                    NaN   \n",
       "671   wanted to say hi. HI!!!\\\" Stop? Send STOP to ...                    NaN   \n",
       "710    this wont even start........ Datz confidence..\"                    NaN   \n",
       "\n",
       "                         Unnamed: 4  \n",
       "95                              NaN  \n",
       "281   just Keep-in-touch\\\" gdeve..\"  \n",
       "444                             NaN  \n",
       "671                             NaN  \n",
       "710                             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print lines where 2, 3 or 4 are not NaN\n",
    "weird_lines = data[data['Unnamed: 2'].notnull() | data['Unnamed: 3'].notnull() | data['Unnamed: 4'].notnull()]\n",
    "weird_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['v2']\n",
    "Y = data['v1'] == 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Super SMS Dataset](https://github.com/smspamresearch/spstudy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67010 entries, 0 to 67009\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   SMSes   67009 non-null  object \n",
      " 1   Labels  67008 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('super_sms_dataset.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 67008 entries, 0 to 67009\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   SMSes   67008 non-null  object \n",
      " 1   Labels  67008 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# remove all values that are nan in either column\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['SMSes']\n",
    "Y = data['Labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    Y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Accuracy, Precision, Recall, F1\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9744316768641497\n",
      "Precision: 0.9735176333807002\n",
      "Recall: 0.9606118546845124\n",
      "F1: 0.9670216861285769\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "eval(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of spam in training set: 0.3908538535337384\n",
      "Accuracy: 0.9707506342336965\n",
      "Precision: 0.9532792004996877\n",
      "Recall: 0.9727214786488209\n",
      "F1: 0.9629022082018928\n"
     ]
    }
   ],
   "source": [
    "percent_spam = np.mean(Y_train)\n",
    "print('Percentage of spam in training set:', percent_spam)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "# Sample weight should be proportional to the percentage of the class in the dataset\n",
    "sample_weight = np.where(Y_train, 1/percent_spam, 1/(1-percent_spam))\n",
    "clf.fit(X_train_tfidf, Y_train, sample_weight=sample_weight)\n",
    "\n",
    "eval(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9701537084017311\n",
      "Precision: 0.951176983435048\n",
      "Recall: 0.9734862970044614\n",
      "F1: 0.9622023434547058\n"
     ]
    }
   ],
   "source": [
    "# Lets resample from the training set until we have 50% spam\n",
    "X_train_resampled = X_train.copy().values\n",
    "Y_train_resampled = Y_train.copy().values\n",
    "\n",
    "total_samples = len(Y_train_resampled)\n",
    "spam_samples = np.sum(Y_train_resampled)\n",
    "ham_samples = total_samples - spam_samples\n",
    "\n",
    "spam_samples_to_add = int(ham_samples - spam_samples)\n",
    "spam_indices = np.where(Y_train_resampled)[0]\n",
    "\n",
    "while spam_samples_to_add > 0:\n",
    "    samples_to_add = min(spam_samples_to_add, spam_samples)\n",
    "    indices_to_add = np.random.choice(spam_indices, samples_to_add)\n",
    "    X_train_resampled = np.concatenate([X_train_resampled, X_train_resampled[indices_to_add]])\n",
    "    Y_train_resampled = np.concatenate([Y_train_resampled, Y_train_resampled[indices_to_add]])\n",
    "    spam_samples_to_add -= samples_to_add\n",
    "    spam_samples += samples_to_add\n",
    "    \n",
    "assert np.sum(Y_train_resampled) == len(Y_train_resampled) / 2\n",
    "    \n",
    "X_train_tfidf_resampled = vectorizer.transform(X_train_resampled)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf_resampled, Y_train_resampled)\n",
    "\n",
    "eval(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam detection using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60381 13135\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def remove_all_non_alphanumeric(s: str) -> str:\n",
    "    return ''.join(c.lower() for c in s if c.isalnum() or c.isspace())\n",
    "\n",
    "words = Counter(remove_all_non_alphanumeric(' '.join(X_train)).split())\n",
    "\n",
    "print(len(words), len([w for w in words if words[w] > 2]))\n",
    "\n",
    "UNKNOWN = '<UNK>'\n",
    "dictionary = {w: i for i, w in enumerate([w for w in words if words[w] > 2])} \n",
    "dictionary[UNKNOWN] = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size) # , num_layers=2, dropout=0.2)\n",
    "        self.hidden2out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        assert len(input) > 0\n",
    "        embedded = self.embedding(input)\n",
    "        lstm_out, _ = self.lstm(embedded.view(len(input), 1, -1))\n",
    "        output = self.hidden2out(lstm_out.sum(dim=0))\n",
    "        return F.sigmoid(output.view(1))\n",
    "    \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] if w in to_ix else to_ix[UNKNOWN] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_label(label):\n",
    "    return torch.tensor([label], dtype=torch.float)\n",
    "\n",
    "def eval_lstm(model, X_test, Y_test, dictionary):\n",
    "    correct = 0\n",
    "    for sentence, label in zip(X_test, Y_test):\n",
    "        sentence_in = prepare_sequence(remove_all_non_alphanumeric(sentence).split(), dictionary)\n",
    "        target = prepare_label(label)\n",
    "        \n",
    "        output = model(sentence_in)\n",
    "        if round(output.item()) == round(target.item()):\n",
    "            correct += 1\n",
    "    print(f'Accuracy: {correct / len(Y_test)}')\n",
    "    \n",
    "def train(model, X_train, Y_train, X_test, Y_test, dictionary, epochs=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        outputs = []\n",
    "        for sentence, label in zip(X_train, Y_train):\n",
    "            model.zero_grad()\n",
    "            input_sentence = remove_all_non_alphanumeric(sentence).split()\n",
    "            if not input_sentence:\n",
    "                continue\n",
    "            sentence_in = prepare_sequence(input_sentence, dictionary)\n",
    "            target = prepare_label(label)\n",
    "            \n",
    "            output = model(sentence_in)\n",
    "            loss = F.binary_cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            outputs.append(output.item())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch}, loss: {total_loss}, mean output: {sum(outputs) / len(outputs)}, min output: {min(outputs)}, max output: {max(outputs)}')\n",
    "        eval_lstm(model, X_test, Y_test, dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2591.0987372331583, mean output: 0.5187632818799145, min output: 0.0006405205349437892, max output: 0.9998452663421631\n",
      "Accuracy: 0.20992822966507177\n",
      "Epoch 1, loss: 2502.0210675670605, mean output: 0.584843852839379, min output: 0.0005746837123297155, max output: 0.9999998807907104\n",
      "Accuracy: 0.3038277511961722\n",
      "Epoch 2, loss: 1909.8660983637255, mean output: 0.5648492125957781, min output: 4.600250395014882e-05, max output: 0.9999997615814209\n",
      "Accuracy: 0.39712918660287083\n",
      "Epoch 3, loss: 1629.6353338320441, mean output: 0.550631104983269, min output: 2.7559319732972654e-06, max output: 1.0\n",
      "Accuracy: 0.4748803827751196\n",
      "Epoch 4, loss: 1384.987472933573, mean output: 0.5389697502289086, min output: 1.432171785609171e-07, max output: 1.0\n",
      "Accuracy: 0.5424641148325359\n",
      "Epoch 5, loss: 1204.5053858667084, mean output: 0.5295956917771394, min output: 6.8041008383090684e-09, max output: 1.0\n",
      "Accuracy: 0.6076555023923444\n",
      "Epoch 6, loss: 1069.234269154125, mean output: 0.5249345883714878, min output: 6.50633713572546e-10, max output: 1.0\n",
      "Accuracy: 0.6561004784688995\n",
      "Epoch 7, loss: 954.3912243856073, mean output: 0.5219279758685083, min output: 1.489368628426746e-10, max output: 1.0\n",
      "Accuracy: 0.6973684210526315\n",
      "Epoch 8, loss: 865.7534911119627, mean output: 0.5188963597273767, min output: 4.2560985985540256e-11, max output: 1.0\n",
      "Accuracy: 0.7254784688995215\n",
      "Epoch 9, loss: 789.0817071107097, mean output: 0.5161567902913412, min output: 3.866935851387643e-12, max output: 1.0\n",
      "Accuracy: 0.7511961722488039\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(4, 1, len(dictionary), 8)\n",
    "\n",
    "train(model, X_train_resampled, Y_train_resampled, X_test, Y_test, dictionary, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on athe results from the paper [Investigating Evasive Techniques in SMS Spam Filtering: A Comparative Analysis of Machine Learning Models](https://ieeexplore.ieee.org/document/10431737):\n",
    "\n",
    "![Results](https://ieeexplore.ieee.org/ielx7/6287639/10380310/10431737/graphical_abstract/access-gagraphic-3364671.jpg)\n",
    "\n",
    "LSTMs simply don't seem to perform well on this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Head:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n",
      "None\n",
      "\n",
      "\n",
      "Describe:\n",
      "              userId        movieId         rating     timestamp\n",
      "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
      "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
      "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
      "min         1.000000       1.000000       0.500000  8.281246e+08\n",
      "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
      "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
      "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
      "max       610.000000  193609.000000       5.000000  1.537799e+09\n",
      "\n",
      "\n",
      "Nulls:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "Unique values:\n",
      "userId: 610 unique values: 1, 2, 3, ..., 608, 609, 610\n",
      "movieId: 9724 unique values: 1, 3, 6, ..., 160836, 163937, 163981\n",
      "rating: 10 unique values: 4.0, 5.0, 3.0, 2.0, 1.0, 4.5, 3.5, 2.5, 0.5, 1.5\n",
      "timestamp: 85043 unique values: 964982703, 964981247, 964982224, ..., 1494273047, 1493846352, 1493846415\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('ratings.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "print('\\n\\nHead:')\n",
    "print(data.head())\n",
    "print('\\n\\nInfo:')\n",
    "print(data.info())\n",
    "print('\\n\\nDescribe:')\n",
    "print(data.describe())\n",
    "print('\\n\\nNulls:')\n",
    "print(data.isnull().sum())\n",
    "print('Unique values:')\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].unique()\n",
    "    if len(unique_values) < 20:\n",
    "        unique_values_str = ', '.join([str(value) for value in unique_values])\n",
    "    else:\n",
    "        # Show first 3 and last 3 unique values\n",
    "        unique_values_str = ', '.join([str(value) for value in unique_values[:3]]) + ', ..., ' + ', '.join([str(value) for value in unique_values[-3:]])\n",
    "    print(f'{column}: {len(unique_values)} unique values: {unique_values_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train size:', 90752, 'Test size:', 10084)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# One hot encoding for user_id and movie_id, i.e. each user_id and movie_id is a feature\n",
    "\n",
    "userId_to_index = {userId: index for index, userId in enumerate(data['userId'].unique())}\n",
    "movieId_to_index = {movieId: index for index, movieId in enumerate(data['movieId'].unique())}\n",
    "\n",
    "data['userId'] = data['userId'].map(userId_to_index)\n",
    "data['movieId'] = data['movieId'].map(movieId_to_index)\n",
    "\n",
    "# X = user_id, movie_id\n",
    "X = data.drop('rating', axis=1).drop('timestamp', axis=1)\n",
    "Y = data['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "'Train size:', len(X_train), 'Test size:', len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing matrix of shape 610 9724 into 5 latent features\n",
      "Step 0 error: 452357.68517562107\n",
      "Step 1 error: 347493.4762258143\n",
      "Step 2 error: 282754.4417922424\n",
      "Step 3 error: 241155.84800813167\n",
      "Step 4 error: 213208.04486387532\n",
      "Step 5 error: 193395.30834678918\n",
      "Step 6 error: 178603.5416157448\n",
      "Step 7 error: 167079.7158458306\n",
      "Step 8 error: 157806.34561946007\n",
      "Step 9 error: 150161.26420485866\n",
      "Step 10 error: 143741.15860407325\n",
      "Step 11 error: 138270.264487537\n",
      "Step 12 error: 133551.66433593602\n",
      "Step 13 error: 129439.96041103097\n",
      "Step 14 error: 125825.01842164177\n",
      "Step 15 error: 122621.73760011667\n",
      "Step 16 error: 119763.2946061895\n",
      "Step 17 error: 117196.50512615671\n",
      "Step 18 error: 114878.54151298106\n",
      "Step 19 error: 112774.55453546366\n",
      "Step 20 error: 110855.91754973293\n",
      "Step 21 error: 109098.91011856106\n",
      "Step 22 error: 107483.7181906737\n",
      "Step 23 error: 105993.66608274305\n",
      "Step 24 error: 104614.62054578305\n",
      "Step 25 error: 103334.52410220925\n",
      "Step 26 error: 102143.02651033837\n",
      "Step 27 error: 101031.19141961927\n",
      "Step 28 error: 99991.26113873505\n",
      "Step 29 error: 99016.46667734186\n",
      "Step 30 error: 98100.87332269909\n",
      "Step 31 error: 97239.25430433196\n",
      "Step 32 error: 96426.98680904396\n",
      "Step 33 error: 95659.96589394029\n",
      "Step 34 error: 94934.53281959378\n",
      "Step 35 error: 94247.41506903032\n",
      "Step 36 error: 93595.6758898642\n",
      "Step 37 error: 92976.67163923621\n",
      "Step 38 error: 92388.01555500821\n",
      "Step 39 error: 91827.5468462376\n",
      "Step 40 error: 91293.30420793299\n",
      "Step 41 error: 90783.50303260627\n",
      "Step 42 error: 90296.51572508112\n",
      "Step 43 error: 89830.85463317283\n",
      "Step 44 error: 89385.1571929503\n",
      "Step 45 error: 88958.17295624132\n",
      "Step 46 error: 88548.75222425489\n",
      "Step 47 error: 88155.83605673308\n",
      "Step 48 error: 87778.44746348927\n",
      "Step 49 error: 87415.68361582232\n",
      "Step 50 error: 87066.70894054245\n",
      "Step 51 error: 86730.74898037118\n",
      "Step 52 error: 86407.0849217672\n",
      "Step 53 error: 86095.04870572976\n",
      "Step 54 error: 85794.01864945458\n",
      "Step 55 error: 85503.4155165983\n",
      "Step 56 error: 85222.69898280638\n",
      "Step 57 error: 84951.36445019917\n",
      "Step 58 error: 84688.94017086334\n",
      "Step 59 error: 84434.98464440013\n",
      "Step 60 error: 84189.08425935853\n",
      "Step 61 error: 83950.85115189433\n",
      "Step 62 error: 83719.92125857616\n",
      "Step 63 error: 83495.95254284299\n",
      "Step 64 error: 83278.62337722786\n",
      "Step 65 error: 83067.63106555675\n",
      "Step 66 error: 82862.69049098513\n",
      "Step 67 error: 82663.53287766578\n",
      "Step 68 error: 82469.90465488449\n",
      "Step 69 error: 82281.56641395796\n",
      "Step 70 error: 82098.29194911924\n",
      "Step 71 error: 81919.86737463449\n",
      "Step 72 error: 81746.09031114956\n",
      "Step 73 error: 81576.76913503172\n",
      "Step 74 error: 81411.72228510458\n",
      "Step 75 error: 81250.77762172779\n",
      "Step 76 error: 81093.7718336887\n",
      "Step 77 error: 80940.54988878261\n",
      "Step 78 error: 80790.96452446523\n",
      "Step 79 error: 80644.8757751169\n",
      "Step 80 error: 80502.15053301942\n",
      "Step 81 error: 80362.6621401847\n",
      "Step 82 error: 80226.29000864894\n",
      "Step 83 error: 80092.9192668576\n",
      "Step 84 error: 79962.44043018934\n",
      "Step 85 error: 79834.74909368096\n",
      "Step 86 error: 79709.74564520556\n",
      "Step 87 error: 79587.33499767662\n",
      "Step 88 error: 79467.4263386532\n",
      "Step 89 error: 79349.93289620883\n",
      "Step 90 error: 79234.77171978704\n",
      "Step 91 error: 79121.86347493823\n",
      "Step 92 error: 79011.13225096892\n",
      "Step 93 error: 78902.50538056376\n",
      "Step 94 error: 78795.91327049742\n",
      "Step 95 error: 78691.28924271624\n",
      "Step 96 error: 78588.56938499125\n",
      "Step 97 error: 78487.692410559\n",
      "Step 98 error: 78388.59952608729\n",
      "Step 99 error: 78291.2343074007\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization(rating_matrix, latent_size, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    num_users, num_movies = rating_matrix.shape\n",
    "    print('Factorizing matrix of shape', num_users, num_movies, 'into', latent_size, 'latent features')\n",
    "    P = np.random.rand(num_users, latent_size)\n",
    "    Q = np.random.rand(num_movies, latent_size)\n",
    "    \n",
    "    for step in range(steps):\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if rating_matrix[i, j] > 0:\n",
    "                    eij = rating_matrix[i, j] - np.dot(P[i, :], Q[j, :])\n",
    "                    for k in range(latent_size):\n",
    "                        P[i, k] = P[i, k] + alpha * (2 * eij * Q[j, k] - beta * P[i, k])\n",
    "                        Q[j, k] = Q[j, k] + alpha * (2 * eij * P[i, k] - beta * Q[j, k])\n",
    "        e = 0\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if rating_matrix[i, j] > 0:\n",
    "                    e = e + pow(rating_matrix[i, j] - np.dot(P[i, :], Q[j, :]), 2)\n",
    "                    for k in range(latent_size):\n",
    "                        e = e + (beta/2) * (pow(P[i, k], 2) + pow(Q[j, k], 2))\n",
    "        print('Step', step, 'error:', e)\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q\n",
    "\n",
    "rating_matrix = data.pivot(index='userId', columns='movieId', values='rating').fillna(0).values\n",
    "P, Q = matrix_factorization(rating_matrix, 5, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550925819710891"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = np.dot(P, Q.T)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    user_id = X_test.iloc[i]['userId']\n",
    "    movie_id = X_test.iloc[i]['movieId']\n",
    "    rating = Y_test.iloc[i]\n",
    "    predicted_rating = predicted_ratings[user_id, movie_id]\n",
    "    accuracy += abs(predicted_rating - rating)\n",
    "    \n",
    "accuracy = accuracy / len(X_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:05<00:00, 263.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.01875025497773092 test loss: 0.02112835071144573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:05<00:00, 252.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.019785074442257244 test loss: 0.0083146509505699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:05<00:00, 256.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train loss: 0.019820128419083163 test loss: 0.007604046692596641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:06<00:00, 218.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train loss: 0.020574794640194505 test loss: 0.0075739157289703984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:06<00:00, 209.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train loss: 0.020674905662223887 test loss: 0.005219828746754799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:06<00:00, 207.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.015233184163667503 test loss: 0.00513040920138028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:05<00:00, 249.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.013161224408314284 test loss: 0.005546506649442534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:05<00:00, 242.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train loss: 0.012507105677037885 test loss: 0.006067094799073525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:06<00:00, 220.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train loss: 0.012164746459746899 test loss: 0.005343550682446163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1418/1418 [00:06<00:00, 228.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train loss: 0.011933462933357411 test loss: 0.006046398061459521\n"
     ]
    }
   ],
   "source": [
    "# Matrix factorization\n",
    "# Objective: min sum (i, j obs) (W_ij - dot(U_i, V_j))^2 + lambda * sum (i, j not obs) dot(U_i, V_j)^2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Linear(n_users, n_factors, bias=True)\n",
    "        self.item_factors = nn.Linear(n_items, n_factors, bias=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, users, items):\n",
    "        # Objective: min sum (i, j obs) (W_ij - dot(U_i, V_j))^2 + lambda * sum (i, j not obs) dot(U_i, V_j)^2\n",
    "        # W_ij = rating\n",
    "        # U_i = user_factors[users]\n",
    "        # V_j = item_factors[items]\n",
    "        # dot(U_i, V_j) = dot(user_factors[users], item_factors[items])\n",
    "        \n",
    "        user = self.user_factors(users)\n",
    "        item = self.item_factors(items)\n",
    "        dot = (user @ item.T).sum(1)\n",
    "        return  dot + self.bias\n",
    "    \n",
    "def RMSE(preds, y):\n",
    "    return np.sqrt(((preds-y)**2).mean())\n",
    "\n",
    "def fit(model, X_train, Y_train, X_test, Y_test, epochs=50, lr=0.001, wd=2e-5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Shuffle X_train and Y_train\n",
    "        idxs = np.random.permutation(len(X_train))\n",
    "        X_train = X_train.iloc[idxs]\n",
    "        Y_train = Y_train.iloc[idxs]\n",
    "        \n",
    "        def calc_loss(users, items, ratings):\n",
    "            # One hot encoding for user and item\n",
    "            users_one_hot = torch.zeros(len(users), n_users)\n",
    "            users_one_hot[range(len(users)), users] = 1\n",
    "            \n",
    "            items_one_hot = torch.zeros(len(items), n_items)\n",
    "            items_one_hot[range(len(items)), items] = 1            \n",
    "            \n",
    "            users = torch.FloatTensor(users_one_hot)\n",
    "            items = torch.FloatTensor(items_one_hot)\n",
    "            ratings = torch.FloatTensor(ratings)\n",
    "            \n",
    "            preds = model(users, items)\n",
    "            return F.l1_loss(preds, ratings)\n",
    "        \n",
    "        train_loss = 0\n",
    "        batch_size = 64\n",
    "        for idx in trange(0, len(X_train), batch_size):\n",
    "            users = X_train['userId'].values[idx:idx+batch_size]\n",
    "            items = X_train['movieId'].values[idx:idx+batch_size]\n",
    "            ratings = Y_train.values[idx:idx+batch_size]\n",
    "            \n",
    "            loss = calc_loss(users, items, ratings)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        users = X_test['userId'].values\n",
    "        items = X_test['movieId'].values\n",
    "        ratings = Y_test.values\n",
    "        loss = calc_loss(users, items, ratings)\n",
    "        print(f'Epoch {epoch} train loss: {train_loss/len(X_train)} test loss: {loss.item() / len(X_test)}')\n",
    "        \n",
    "        \n",
    "n_users = X['userId'].nunique()\n",
    "n_items = X['movieId'].nunique()\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=20)\n",
    "fit(model, X_train, Y_train, X_test, Y_test, epochs=5, lr=0.01, wd=1e-5)\n",
    "fit(model, X_train, Y_train, X_test, Y_test, epochs=5, lr=0.001, wd=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
